{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very Simple Neural Network\n",
    "\n",
    "This network can be used to demonstrate how to implement the backprop algorithm.\n",
    "This notebook represents the code associated with the writeup at LINK.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import sys\n",
    "print(sys.version_info)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_neurons = [8,5]\n",
    "n_hidden_layers = len(n_hidden_neurons)\n",
    "nlayers = n_hidden_layers+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrossEntropy():\n",
    "        \n",
    "    def error(self, y,a):\n",
    "        return -y*np.log(a) - (1.-y)*np.log(1. - a)\n",
    "    \n",
    "    def derror(self,a, y):\n",
    "        return a - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InputLayer():\n",
    "    def __init__(self, n=2):\n",
    "        self.z = np.zeros(shape=(n,1))\n",
    "    def forward(self, x):\n",
    "        self.z = x\n",
    "        return x\n",
    "    def last_activ(self):\n",
    "        return self.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OutputLayer():\n",
    "    def __init__(self, n=1, nprev=5, cost=CrossEntropy() ):\n",
    "        self.N = n\n",
    "        self.Nprev = nprev\n",
    "        \n",
    "        self.z = np.zeros(shape=(n,1))\n",
    "        \n",
    "        self.b = np.random.uniform(low=0., high=1., size=(n,1))\n",
    "        self.bupdates = np.zeros_like(self.b)\n",
    "        \n",
    "        # W represents the matrix of weights from the PREVIOUS layer to THIS layer\n",
    "        self.W = np.random.uniform(low=0., high=1., size=(n,nprev))\n",
    "        self.Wupdates = np.zeros_like(self.W)\n",
    "        \n",
    "        self.cost_ = cost\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.z = (self.W @ x).reshape(self.N,1) + self.b\n",
    "        return sigmoid(self.z)\n",
    "    \n",
    "    def last_activ(self):\n",
    "        return sigmoid(self.z)\n",
    "    \n",
    "    def backward(self, y):\n",
    "        return self.cost_.derror(sigmoid(self.z),y)*sigmoid(self.z)*( 1.0 - sigmoid(self.z))\n",
    "    \n",
    "    def update(self):\n",
    "        self.b -= self.bupdates\n",
    "        self.W -= self.Wupdates\n",
    "        self.bupdates = np.zeros_like(self.b)\n",
    "        self.Wupdates = np.zeros_like(self.W)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SigmoidLayer():\n",
    "    def __init__(self, n=5, nprev=5):\n",
    "        self.N = n\n",
    "        self.Nprev = nprev\n",
    "        \n",
    "        self.z = np.zeros(shape=(n,1))\n",
    "        \n",
    "        self.b = np.random.uniform(low=0., high=1., size=(n,1))\n",
    "        self.bupdates = np.zeros_like(self.b)\n",
    "        \n",
    "        # W represents the matrix of weights from the PREVIOUS layer to THIS layer\n",
    "        self.W = np.random.uniform(low=0., high=1., size=(n,nprev))\n",
    "        self.Wupdates = np.zeros_like(self.W)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.z = (self.W @ x).reshape(self.N,1) + self.b\n",
    "        return sigmoid(self.z)\n",
    "    \n",
    "    def last_activ(self):\n",
    "        return sigmoid(self.z)\n",
    "    \n",
    "    def backward(self, W, dLdz):\n",
    "        '''Note: this W is NOT self.W, but the one from the downstream layer!'''\n",
    "        return (W.T @ dLdz)*sigmoid(self.z)*(1. - sigmoid(self.z))\n",
    "    \n",
    "    def update(self):\n",
    "        self.b -= self.bupdates\n",
    "        self.W -= self.Wupdates\n",
    "        self.bupdates = np.zeros_like(self.b)\n",
    "        self.Wupdates = np.zeros_like(self.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CostFunction = CrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = []\n",
    "layers.append( InputLayer(n_input) )\n",
    "nprev = n_input\n",
    "for n in n_hidden_neurons:\n",
    "    layers.append(SigmoidLayer(n, nprev))\n",
    "    nprev = n\n",
    "layers.append(OutputLayer(1,nprev,CostFunction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 2\n",
    "\n",
    "X, y = make_classification(n_samples=800, n_features=n_input, \n",
    "                           n_informative=n_input, n_redundant=0,\n",
    "                           n_classes=2, n_clusters_per_class=1, \n",
    "                           random_state=42023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 2\n",
    "X, y = make_moons( n_samples=800, noise=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(X[:,0],X[:,1],c=y, s=75, linewidths=0, cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(X_train[:,0],X_train[:,1],c=y_train, s=75, linewidths=0, cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 5.0\n",
    "n_epochs = 50\n",
    "\n",
    "training_error = []\n",
    "validation_error = []\n",
    "    \n",
    "for i in range(n_epochs):\n",
    "\n",
    "    errors = []\n",
    "    for idx, data_sample in enumerate(X_train):\n",
    "        # feedforward\n",
    "        a = layers[0].forward(data_sample)\n",
    "        for i in range(1,nlayers):\n",
    "            a = layers[i].forward(a)\n",
    "\n",
    "        errors.append(CostFunction.error(y_train[idx], a))\n",
    "    \n",
    "        # backprop\n",
    "        error = layers[nlayers-1].backward(y_train[idx])\n",
    "        layers[nlayers-1].Wupdates = alpha*np.outer(error, layers[nlayers-2].last_activ() )\n",
    "        layers[nlayers-1].bupdates = alpha*error\n",
    "       \n",
    "        for i in range(nlayers-2,0,-1):\n",
    "            error = layers[i].backward(layers[i+1].W, error)\n",
    "            layers[i].Wupdates = alpha*np.outer(error , layers[i-1].last_activ())\n",
    "            layers[i].bupdates = alpha*error\n",
    "            \n",
    "        for i in range(1,nlayers):\n",
    "            layers[i].update()\n",
    "            \n",
    "    training_error.append(np.mean(errors))\n",
    "    \n",
    "    # validation\n",
    "    errors = []\n",
    "    for idx, data_sample in enumerate(X_test):\n",
    "        # feedforward\n",
    "        a = layers[0].forward(data_sample)\n",
    "        for i in range(1,nlayers):\n",
    "            a = layers[i].forward(a)\n",
    "        errors.append(CostFunction.error(y_test[idx], a[0]))\n",
    "    validation_error.append(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(range(n_epochs), training_error, '.-')\n",
    "plt.plot(range(n_epochs), validation_error, '.-')\n",
    "plt.legend(['training','validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(layers, x):\n",
    "    a = x\n",
    "    for i in range(nlayers):\n",
    "        a = layers[i].forward(a)\n",
    "        \n",
    "    return a > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(inference(layers, np.array([3.5, -3.0]).reshape(2,1)))\n",
    "print(inference(layers, np.array([-2.0, 2.0]).reshape(2,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h=0.2\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = np.zeros_like(xx)\n",
    "\n",
    "# here \"model\" is your model's prediction (classification) function\n",
    "for ix, x in enumerate(xx[0,:]):\n",
    "    for iy, yv in enumerate(yy[:,0]):\n",
    "        Z[iy,ix] = inference(layers, np.r_[x, yv])[0]\n",
    "\n",
    "# Put the result into a color plot\n",
    "#Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.contourf(xx, yy, Z, LevelStep=1, cmap=plt.cm.Paired)\n",
    "plt.colorbar(ticks=[-1,0,1])\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, s=75, linewidth=1,  edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
