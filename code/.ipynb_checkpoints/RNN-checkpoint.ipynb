{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import sys\n",
    "print(sys.version_info)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_neurons = [8,5]\n",
    "n_hidden_layers = len(n_hidden_neurons)\n",
    "nlayers = n_hidden_layers+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unroll_factor = n_discr_points - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanSquareError():\n",
    "        \n",
    "    def error(self, y, a):\n",
    "        return (a-y)**2\n",
    "    \n",
    "    def derror(self,a, y):\n",
    "        return 2*(a-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RecurrentInputLayer():\n",
    "    \"\"\"Designed to be compatible with Recurrent layers\"\"\"\n",
    "    def __init__(self, n=2, unroll_fac=1):\n",
    "        self.N = n\n",
    "        self.unroll_ = unroll_fac\n",
    "        self.h = np.zeros(shape=(n,self.unroll_+1))\n",
    "    def forward(self, x, tt):\n",
    "        self.h[:,tt+1] = np.array(x).reshape(self.N, 1)\n",
    "        return self.h[:,tt+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OutputLayer():\n",
    "    def __init__(self, n=1, nprev=5, cost=MeanSquareError() ):\n",
    "        self.N = n\n",
    "        self.Nprev = nprev\n",
    "        \n",
    "        self.z = np.zeros(shape=(n,1))\n",
    "        \n",
    "        self.b = np.random.uniform(low=0., high=1., size=(n,1))\n",
    "        self.bupdates = np.zeros_like(self.b)\n",
    "        \n",
    "        # W represents the matrix of weights from the PREVIOUS layer to THIS layer\n",
    "        self.W = np.random.uniform(low=0., high=1., size=(n,nprev))\n",
    "        self.Wupdates = np.zeros_like(self.W)\n",
    "        \n",
    "        self.cost_ = cost\n",
    "        \n",
    "    def forward(self, x, tt=0):\n",
    "        self.z = (self.W @ x).reshape(self.N,1) + self.b\n",
    "        return self.z\n",
    "    \n",
    "    def backward(self, y):\n",
    "        return self.cost_.derror(self.z,y), self.cost_.derror(self.z,y)*self.W\n",
    "        \n",
    "    \n",
    "    def update(self):\n",
    "        self.b -= self.bupdates\n",
    "        self.W -= self.Wupdates\n",
    "        self.bupdates = np.zeros_like(self.b)\n",
    "        self.Wupdates = np.zeros_like(self.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RecurrentSigmoidLayer():\n",
    "    def __init__(self, n=5, nprev=5, unroll_fac=1):\n",
    "        self.N = n\n",
    "        self.Nprev = nprev\n",
    "        self.unroll_ = unroll_fac\n",
    "        \n",
    "        self.h = np.random.uniform(low=0., high=1., size=(self.N,self.unroll_+1))\n",
    "        \n",
    "        self.b = np.random.uniform(low=0., high=1., size=(self.N,1))\n",
    "        self.bupdates = np.zeros_like(self.b)\n",
    "        \n",
    "        # W represents the matrix of weights from the PREVIOUS layer to THIS layer\n",
    "        self.W = np.random.uniform(low=0., high=1., size=(self.N,self.Nprev))\n",
    "        self.Wupdates = np.zeros_like(self.W)\n",
    "        \n",
    "        self.Whh = np.random.uniform(low=0., high=1., size=(self.N,self.N))\n",
    "        self.Whhupdates = np.zeros_like(self.Whh)\n",
    "        \n",
    "    def forward(self, x, tt):\n",
    "        \n",
    "        x = np.array([x])\n",
    "        x = x.reshape(self.Nprev, 1)\n",
    "        \n",
    "        self.h[:,tt+1] = sigmoid( np.ravel(\n",
    "                          self.W @ x + self.Whh @ self.h[:,tt].reshape(self.N,1) + self.b) )            \n",
    "   \n",
    "        return self.h[:,tt+1]\n",
    "    \n",
    "    def backward(self, deltaL, deltaH, tt):\n",
    "        \n",
    "        delta = deltaL + deltaH\n",
    "        delta = delta.reshape(1,self.N)\n",
    "        h = self.h[:,tt+1].reshape(1,self.N)\n",
    "        \n",
    "        update_fac = delta * h * (1. - h)\n",
    "\n",
    "        Ldelta = ( delta * h * (1. - h) ) @ self.W\n",
    "\n",
    "        Hdelta =(  delta * h * (1. - h) ) @ self.Whh    \n",
    "\n",
    "        return update_fac, Ldelta, Hdelta\n",
    "\n",
    "\n",
    "    \n",
    "    def update(self):\n",
    "        self.b -= self.bupdates\n",
    "        self.W -= self.Wupdates\n",
    "        self.Whh -= self.Whhupdates\n",
    "        self.bupdates = np.zeros_like(self.b)\n",
    "        self.Wupdates = np.zeros_like(self.W)        \n",
    "        self.Whhupdates = np.zeros_like(self.Whh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CostFunction = MeanSquareError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = []\n",
    "layers.append( RecurrentInputLayer(1,unroll_factor) )\n",
    "nprev = 1\n",
    "for n in n_hidden_neurons:\n",
    "    layers.append(RecurrentSigmoidLayer(n, nprev, unroll_factor))\n",
    "    nprev = n\n",
    "layers.append(OutputLayer(1,nprev,CostFunction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "n_epochs = 100\n",
    "\n",
    "training_error = []\n",
    "validation_error = []\n",
    "    \n",
    "for i in range(n_epochs):\n",
    "\n",
    "    errors = []\n",
    "    for idx, data_sample in enumerate(y_train):\n",
    "        \n",
    "        # feedforward\n",
    "        for t in range(unroll_factor):\n",
    "            a = data_sample[t]\n",
    "            for i in range(0,nlayers):\n",
    "                a = layers[i].forward(a,t)\n",
    "\n",
    "        # now a holds the prediction for the next value\n",
    "        # the true next value is data_sample[unroll_factor]\n",
    "        errors.append(CostFunction.error(data_sample[unroll_factor], a))\n",
    "    \n",
    "        ###########################################\n",
    "        # backprop through time\n",
    "        \n",
    "        # output layer: no time        \n",
    "        update_fac, delta = layers[nlayers-1].backward(data_sample[unroll_factor])     \n",
    "        layers[nlayers-1].Wupdates = \\\n",
    "            alpha*np.outer(update_fac, layers[nlayers-2].h[:,-1] )\n",
    "        layers[nlayers-1].bupdates = alpha*update_fac   \n",
    "        \n",
    "        # deltaL_dict[l][t] is the error signal that layer l passes to layer (l-1) at time t\n",
    "        # deltaH_dict[l][t] is the error signal that layer l passes to itself from time t to t-1\n",
    "        deltaL_dict = dict()\n",
    "        deltaH_dict = dict()\n",
    "        for l in range(nlayers-1,0,-1):\n",
    "            deltaL_dict[l] = dict()\n",
    "            deltaH_dict[l] = dict()\n",
    "            for t in range(unroll_factor,-1,-1):\n",
    "                deltaL_dict[l][t] = np.zeros( shape=(1, layers[l].Nprev) )\n",
    "                deltaH_dict[l][t] = np.zeros( shape=(1, layers[l].N) )\n",
    "\n",
    "        deltaL_dict[nlayers-1][unroll_factor-1] = delta\n",
    "        \n",
    "        for l in range(nlayers-2,0,-1):\n",
    "            for t in range(unroll_factor-1,-1,-1):\n",
    "                update_fac, Ldelta, Hdelta = layers[l].backward(deltaL_dict[l+1][t], deltaH_dict[l][t+1], t)\n",
    "                deltaL_dict[l][t] = Ldelta\n",
    "                deltaH_dict[l][t] = Hdelta\n",
    "                layers[l].Wupdates   += alpha*np.outer(update_fac, layers[l-1].h[:,t+1] )\n",
    "                layers[l].Whhupdates += alpha*np.outer(update_fac, layers[l].h[:,t] )\n",
    "                layers[l].bupdates   += alpha*update_fac.reshape(layers[l].bupdates.shape[0],\n",
    "                                                                 layers[l].bupdates.shape[1])\n",
    "                   \n",
    "        for i in range(1,nlayers):\n",
    "            layers[i].update()\n",
    "            \n",
    "    training_error.append(np.mean(errors))\n",
    "    \n",
    "    # validation\n",
    "    errors = []\n",
    "    for idx, data_sample in enumerate(y_test):\n",
    "        # feedforward\n",
    "        for t in range(unroll_factor):\n",
    "            a = data_sample[t]\n",
    "            for i in range(0,nlayers):\n",
    "                a = layers[i].forward(a,t)\n",
    "        errors.append(CostFunction.error(data_sample[unroll_factor], a[0]))\n",
    "    validation_error.append(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(range(n_epochs), training_error, '.-')\n",
    "plt.plot(range(n_epochs), validation_error, '.-')\n",
    "plt.legend(['training','validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(layers, data_sample):\n",
    "    # feedforward\n",
    "    for t in range(unroll_factor):\n",
    "        a = data_sample[t]\n",
    "        for i in range(0,nlayers):\n",
    "            a = layers[i].forward(a,t)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(y_test[i,:])\n",
    "    print(inference(layers,y_test[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sin(n_samples=400, n_discr_points = 10):\n",
    "    x = np.arange(start=0.0, stop=2.0*np.pi, step=2.0*np.pi/n_discr_points)\n",
    "    omega = np.random.uniform(1.0, 4.0, (n_samples, x.shape[0]) )\n",
    "    return np.sin(omega*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sum(n_samples=600, n_discr_points=5):\n",
    "    Y = np.random.randint(low=0,high=2,size=(n_samples,n_discr_points-1))\n",
    "    Y = np.c_[Y, np.sum(Y, axis=1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 600\n",
    "n_discr_points = 8\n",
    "y = make_sum(n_samples, n_discr_points)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_train, y_test = train_test_split( y, test_size=0.33, random_state=42 )\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
